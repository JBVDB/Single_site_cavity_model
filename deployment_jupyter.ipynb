{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkeuxIuAZFxM"
   },
   "source": [
    "## Import packages, modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1534,
     "status": "ok",
     "timestamp": 1622120819493,
     "user": {
      "displayName": "Jean-Baptiste Van Den Broucke",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtaGEPCQbJCZvlt0pnd8zp8Lr7aa-YohqINw_9vg=s64",
      "userId": "13204566160110856358"
     },
     "user_tz": -120
    },
    "id": "M_kov-C7ZdkE"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import timeit\n",
    "import re\n",
    "import pickle\n",
    "from typing import Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import tempfile\n",
    "from io import BytesIO, StringIO\n",
    "\n",
    "import Bio.PDB\n",
    "import Bio.PDB.Polypeptide\n",
    "import Bio.PDB.vectors\n",
    "import Bio.SeqIO\n",
    "from Bio.PDB.Polypeptide import index_to_one\n",
    "\n",
    "# packages necessary for cleaning the PDB files (see cavity_model_pipeline.ipynb)\n",
    "import simtk\n",
    "import simtk.openmm\n",
    "import simtk.openmm.app\n",
    "import simtk.unit\n",
    "\n",
    "from cavity_model import (\n",
    "    CavityModel,\n",
    "    ResidueEnvironment,\n",
    "    ResidueEnvironmentsDataset,\n",
    "    DownstreamModel,\n",
    "    ToTensor,\n",
    "    DDGDataset,\n",
    "    DDGToTensor,\n",
    "    DownstreamModel,\n",
    ")\n",
    "\n",
    "from helpers import (\n",
    "    _augment_with_reverse_mutation,\n",
    "    _populate_dfs_with_nlls_and_nlfs,\n",
    "    _populate_dfs_with_resenvs,\n",
    "    _train_loop,\n",
    "    _train_val_split,\n",
    "    _get_ddg_training_dataloaders,\n",
    "    _get_ddg_validation_dataloaders,\n",
    "    _train_downstream_and_evaluate,\n",
    "    _predict_with_downstream,\n",
    "    _eval_loop\n",
    ")\n",
    "\n",
    "from visualization import scatter_pred_vs_true, plot_validation_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnwPnabm0lKg"
   },
   "source": [
    "# Preprocess .pdb files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ImaLA3EU45MB"
   },
   "outputs": [],
   "source": [
    "from pdb_parser_scripts.clean_pdb import clean_pdb\n",
    "from pdb_parser_scripts.extract_environments import extract_environments\n",
    "# import pdb_parser_scripts.grid\n",
    "\n",
    "import traceback\n",
    "import pdbfixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TI9QN2L30qEM"
   },
   "outputs": [],
   "source": [
    "pdb_files = glob.glob(\"data/pdbs/raw/*\")\n",
    "pdb_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data/pdbs/cleaned\n",
    "!mkdir data/pdbs/parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55244,
     "status": "ok",
     "timestamp": 1620924784032,
     "user": {
      "displayName": "Jean-Baptiste Van Den Broucke",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtaGEPCQbJCZvlt0pnd8zp8Lr7aa-YohqINw_9vg=s64",
      "userId": "13204566160110856358"
     },
     "user_tz": -120
    },
    "id": "aZA9fb6O4teh",
    "outputId": "3fe23b79-8f9b-4e62-a587-28c2e8ad47b3"
   },
   "outputs": [],
   "source": [
    "n_files = len(pdb_files)\n",
    "fails = []\n",
    "for i, pdb_filename in enumerate(pdb_files):\n",
    "    try:\n",
    "\n",
    "        clean_pdb(pdb_filename, \"data/pdbs/cleaned\", \"reduce/reduce\")\n",
    "\n",
    "        pdb_filename = os.path.basename(pdb_filename)\n",
    "        pdb_id = pdb_filename.split(\".\")[0]\n",
    "\n",
    "        extract_environments(f\"data/pdbs/cleaned/{pdb_id}_clean.pdb\",\n",
    "                            pdb_id=pdb_id,\n",
    "                            out_dir=\"data/pdbs/parsed\")\n",
    "        print(f\"{pdb_filename} cleaned & parsed successfully ({i+1}/{n_files})\")\n",
    "    except Exception:\n",
    "        print(f\"{pdb_filename} failed. Nb: {i+1}.\")\n",
    "        fails.append(pdb_filename)\n",
    "\n",
    "        error_msg = traceback.format_exc()\n",
    "        print(error_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-_5MSGdq3Yp"
   },
   "source": [
    "# Cavity + DS model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset of all possible single-site mutants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1110,
     "status": "ok",
     "timestamp": 1622127495363,
     "user": {
      "displayName": "Jean-Baptiste Van Den Broucke",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtaGEPCQbJCZvlt0pnd8zp8Lr7aa-YohqINw_9vg=s64",
      "userId": "13204566160110856358"
     },
     "user_tz": -120
    },
    "id": "_Ybt69JBIH1G"
   },
   "outputs": [],
   "source": [
    "# Enter protein of interest\n",
    "prot_interest = \"\"\n",
    "\n",
    "# Create temporary residue environment datasets as dicts to more easily match ddG data\n",
    "parsed_pdbs_wildcards = {\n",
    "    prot_interest : f\"data/pdbs/parsed/{prot_interest}_coordinate_features.npz\", \n",
    "}\n",
    "\n",
    "\n",
    "resenv_datasets_look_up = {}\n",
    "for dataset_key, pdbs_wildcard in parsed_pdbs_wildcards.items():\n",
    "    parsed_pdb_filenames = sorted(glob.glob(pdbs_wildcard))\n",
    "\n",
    "    dataset = ResidueEnvironmentsDataset(parsed_pdb_filenames, transformer=None)\n",
    "    dataset_look_up = {}\n",
    "    for resenv in dataset:\n",
    "        key = (\n",
    "            f\"{resenv.pdb_id}{resenv.chain_id}_{resenv.pdb_residue_number}\"\n",
    "            f\"{index_to_one(resenv.restype_index)}\" #  Index corresponding to one-letter-encoding amino acid.\n",
    "        )\n",
    "        dataset_look_up[key] = resenv\n",
    "    resenv_datasets_look_up[dataset_key] = dataset_look_up # dict of datasets dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1622127496751,
     "user": {
      "displayName": "Jean-Baptiste Van Den Broucke",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtaGEPCQbJCZvlt0pnd8zp8Lr7aa-YohqINw_9vg=s64",
      "userId": "13204566160110856358"
     },
     "user_tz": -120
    },
    "id": "4zdjKN4_NQwk"
   },
   "outputs": [],
   "source": [
    "# Consider all potential mutations 222 x 22\n",
    "prot_infos = np.load(parsed_pdbs_wildcards[prot_interest])\n",
    "\n",
    "seq_wt_index = np.argmax(prot_infos[\"aa_onehot\"], axis=1)\n",
    "chain_boundary_indices = prot_infos[\"chain_boundary_indices\"]\n",
    "res_numbers = prot_infos[\"residue_numbers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1622127497684,
     "user": {
      "displayName": "Jean-Baptiste Van Den Broucke",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtaGEPCQbJCZvlt0pnd8zp8Lr7aa-YohqINw_9vg=s64",
      "userId": "13204566160110856358"
     },
     "user_tz": -120
    },
    "id": "_h16JEs1QD3d"
   },
   "outputs": [],
   "source": [
    "idx_to_one = Bio.PDB.Polypeptide.index_to_one\n",
    "\n",
    "chainid = []\n",
    "variant = []\n",
    "\n",
    "for i, (res_nb, restype_idx) in enumerate(zip(res_numbers, seq_wt_index)):\n",
    "\n",
    "    for j, boundary in enumerate(chain_boundary_indices):\n",
    "        if i < boundary:\n",
    "            chainid.extend([chr(65 + j-1) for _ in range(19)])\n",
    "            break\n",
    "\n",
    "    variant.extend([f\"{idx_to_one(restype_idx)}{res_nb}{idx_to_one(x)}\" for x in range(20) if x != restype_idx])\n",
    "\n",
    "pd.DataFrame({\"pdbid\": prot_interest, \"chainid\": chainid, \"variant\": variant})\n",
    "\n",
    "ddg_data_dict = OrderedDict()\n",
    "\n",
    "# Parse pdb_id the same way as cavity_model.ResidueEnvironmentDataset (0:4).\n",
    "ddg_data_dict[prot_interest] = pd.DataFrame({\"pdbid\": prot_interest.split(\"_\")[0][0:4],\n",
    "                                             \"chainid\": chainid,\n",
    "                                             \"variant\": variant})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 705,
     "status": "ok",
     "timestamp": 1622127499204,
     "user": {
      "displayName": "Jean-Baptiste Van Den Broucke",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtaGEPCQbJCZvlt0pnd8zp8Lr7aa-YohqINw_9vg=s64",
      "userId": "13204566160110856358"
     },
     "user_tz": -120
    },
    "id": "nQ6PuhDkTUX8",
    "outputId": "6543f2c4-5f6f-4ca5-bfab-7b2da415f45b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_populate_dfs_with_resenvs(ddg_data_dict, resenv_datasets_look_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predictions of the Cavity model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3538,
     "status": "ok",
     "timestamp": 1622127502738,
     "user": {
      "displayName": "Jean-Baptiste Van Den Broucke",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtaGEPCQbJCZvlt0pnd8zp8Lr7aa-YohqINw_9vg=s64",
      "userId": "13204566160110856358"
     },
     "user_tz": -120
    },
    "id": "eD3EDBh9MGO1"
   },
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"\n",
    "BATCH_SIZE = 10\n",
    "EPS = 1e-9\n",
    "\n",
    "# Load best performing cavity model from previos training\n",
    "cavity_model_infer_net = CavityModel(DEVICE).to(DEVICE)\n",
    "cavity_model_infer_net.load_state_dict(torch.load(\"models/cavity_model.pt\"))\n",
    "cavity_model_infer_net.eval()\n",
    "\n",
    "_populate_dfs_with_nlls_and_nlfs( # performs the predictions and does IN PLACE modification of the ddg_data_dict dataset (does not RETURN anything)\n",
    "    ddg_data_dict, cavity_model_infer_net, DEVICE, BATCH_SIZE, EPS\n",
    ")\n",
    "\n",
    "ddg_data_dict[prot_interest].rename({\"ddg_pred_no_ds\": \"ddg\"},\n",
    "                                    axis=1,\n",
    "                                    inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ddG predictions with site-saturation library: \"Mayo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1770,
     "status": "ok",
     "timestamp": 1622127504895,
     "user": {
      "displayName": "Jean-Baptiste Van Den Broucke",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtaGEPCQbJCZvlt0pnd8zp8Lr7aa-YohqINw_9vg=s64",
      "userId": "13204566160110856358"
     },
     "user_tz": -120
    },
    "id": "yXRfRv-wD6D6",
    "outputId": "fbde276b-2c61-4989-d623-72d15952606b"
   },
   "outputs": [],
   "source": [
    "# load downstream model\n",
    "downstream_model_net = DownstreamModel().to(DEVICE)\n",
    "# downstream_model_net = DownstreamModel().to(DEVICE)\n",
    "\n",
    "# downstream_model_net.eval()\n",
    "downstream_model_net.load_state_dict(torch.load(\"models/ds_model_mayo.pt\"))\n",
    "\n",
    "# get validation dataloader\n",
    "ddg_dataloaders_val_dict = _get_ddg_validation_dataloaders(ddg_data_dict)\n",
    "\n",
    "# get predictions\n",
    "ddg_pred = _predict_with_downstream(ddg_dataloaders_val_dict,\n",
    "                                    downstream_model_net,\n",
    "                                    DEVICE)\n",
    "\n",
    "for prot_family in ddg_pred.keys():\n",
    "    ddg_data_dict[prot_family][\"ddg_ds_mayo\"] = ddg_pred[prot_family]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ddG predictions with site-saturation library: \"Guerois\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2334,
     "status": "ok",
     "timestamp": 1620925748659,
     "user": {
      "displayName": "Jean-Baptiste Van Den Broucke",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtaGEPCQbJCZvlt0pnd8zp8Lr7aa-YohqINw_9vg=s64",
      "userId": "13204566160110856358"
     },
     "user_tz": -120
    },
    "id": "S6kTXhj1l8Vf",
    "outputId": "79f064f7-e12a-436c-b0ae-31efa5e547d6"
   },
   "outputs": [],
   "source": [
    "# load downstream model\n",
    "downstream_model_net = DownstreamModel().to(DEVICE)\n",
    "# downstream_model_net = DownstreamModel().to(DEVICE)\n",
    "\n",
    "# downstream_model_net.eval()\n",
    "downstream_model_net.load_state_dict(torch.load(\"models/ds_model_guerois.pt\"))\n",
    "\n",
    "# get validation dataloader\n",
    "ddg_dataloaders_val_dict = _get_ddg_validation_dataloaders(ddg_data_dict)\n",
    "\n",
    "# get predictions\n",
    "ddg_pred = _predict_with_downstream(ddg_dataloaders_val_dict,\n",
    "                                    downstream_model_net,\n",
    "                                    DEVICE)\n",
    "\n",
    "for prot_family in ddg_pred.keys():\n",
    "    ddg_data_dict[prot_family][\"ddg_ds_guerois\"] = ddg_pred[prot_family]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EtalNiC3mLH2"
   },
   "outputs": [],
   "source": [
    "ddg_data_dict[prot_family].to_csv(f\"results/{prot_interest}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hWFS7_Zrwl2"
   },
   "source": [
    "# Visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrz-6ax2O505"
   },
   "source": [
    "## Requirements for stability analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1xQUaEJ9I-8O"
   },
   "outputs": [],
   "source": [
    "# Source code for ssbio.protein.structure.properties.dssp from: https://ssbio.readthedocs.io/en/latest/_modules/ssbio/protein/structure/properties/dssp.html\n",
    "# the code takes a pdb file, runs DSSP on it, turns it into a csv file (.dssp.df) i.e. returns a dataframe.\n",
    "import logging\n",
    "import ssbio.utils # structural systems biology tools\n",
    "from collections import defaultdict\n",
    "from six import iteritems\n",
    "from Bio.PDB.DSSP import dssp_dict_from_pdb_file\n",
    "from Bio.PDB.DSSP import residue_max_acc\n",
    "from Bio.PDB.Polypeptide import aa1\n",
    "from Bio.PDB.Polypeptide import one_to_three\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# for plotting\n",
    "import plotly \n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot #offline\n",
    "\n",
    "\n",
    "def get_dssp_df_on_file(pdb_file, outfile=None, outdir=None, outext='_dssp.df', force_rerun=False):\n",
    "    \"\"\"Run DSSP directly on a structure file with the Biopython method Bio.PDB.DSSP.dssp_dict_from_pdb_file\n",
    "\n",
    "    Avoids errors like: PDBException: Structure/DSSP mismatch at <Residue MSE het=  resseq=19 icode= >\n",
    "    by not matching information to the structure file (DSSP fills in the ID \"X\" for unknown residues)\n",
    "\n",
    "    Args:\n",
    "        pdb_file: Path to PDB file\n",
    "        outfile: Name of output file\n",
    "        outdir: Path to output directory\n",
    "        outext: Extension of output file\n",
    "        force_rerun: If DSSP should be rerun if the outfile exists\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DSSP results summarized\n",
    "\n",
    "    \"\"\"\n",
    "    # TODO: function unfinished\n",
    "    # Create the output file name\n",
    "    outfile = ssbio.utils.outfile_maker(inname=pdb_file, outname=outfile, outdir=outdir, outext=outext)\n",
    "\n",
    "    if ssbio.utils.force_rerun(flag=force_rerun, outfile=outfile):\n",
    "        try:\n",
    "            d = dssp_dict_from_pdb_file(pdb_file)\n",
    "            \n",
    "        except: #  Exception('DSSP failed to produce an output')\n",
    "            log.error('{}: unable to run DSSP'.format(pdb_file))\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        appender = []\n",
    "        # TODO: WARNING: d is slightly different than when using function get_dssp_df\n",
    "        \n",
    "        for k in d[1]:\n",
    "            to_append = []\n",
    "            y = d[0][k]\n",
    "            chain = k[0]\n",
    "            residue = k[1]\n",
    "            het = residue[0]\n",
    "            resnum = residue[1]\n",
    "            icode = residue[2]\n",
    "            to_append.extend([chain, resnum, icode])\n",
    "            to_append.extend(y)\n",
    "            appender.append(to_append)\n",
    "\n",
    "        cols = ['chain', 'resnum', 'icode',\n",
    "                'aa', 'ss', 'exposure_rsa', 'phi', 'psi', 'dssp_index',\n",
    "                'NH_O_1_relidx', 'NH_O_1_energy', 'O_NH_1_relidx',\n",
    "                'O_NH_1_energy', 'NH_O_2_relidx', 'NH_O_2_energy',\n",
    "                'O_NH_2_relidx', 'O_NH_2_energy']\n",
    "      \n",
    "        df = pd.DataFrame.from_records(appender, columns=cols)\n",
    "\n",
    "        # Adding additional columns\n",
    "        df = df[df['aa'].isin(list(aa1))]\n",
    "        df['aa_three'] = df['aa'].apply(one_to_three)\n",
    "        df['max_acc'] = df['aa_three'].map(residue_max_acc['Sander'].get) # use 'Sander', 'Wilke', or 'Miller, dictionnary of ASA (accessible surface area)\n",
    "        df[['exposure_rsa', 'max_acc']] = df[['exposure_rsa', 'max_acc']].astype(float)\n",
    "        df['exposure_asa'] = df['exposure_rsa'] * df['max_acc']\n",
    "\n",
    "        df.to_csv(outfile)\n",
    "    else:\n",
    "        log.debug('{}: already ran DSSP and force_rerun={}, loading results'.format(outfile, force_rerun))\n",
    "        df = pd.read_csv(outfile, index_col=0)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def secondary_structure_summary(dssp_df):\n",
    "    \"\"\"Summarize the secondary structure content of the DSSP dataframe for each chain.\n",
    "\n",
    "    Args:\n",
    "        dssp_df: Pandas DataFrame of parsed DSSP results\n",
    "\n",
    "    Returns:\n",
    "        dict: Chain to secondary structure summary dictionary\n",
    "\n",
    "    \"\"\"\n",
    "    chains = dssp_df.chain.unique()\n",
    "\n",
    "    infodict = {}\n",
    "    for chain in chains:\n",
    "        expoinfo = defaultdict(int)\n",
    "        chain_df = dssp_df[dssp_df.chain == chain]\n",
    "        counts = chain_df.ss.value_counts()\n",
    "        total = float(len(chain_df))\n",
    "\n",
    "        for ss, count in iteritems(counts):\n",
    "            if ss == '-':\n",
    "                expoinfo['percent_C-dssp'] = count/total\n",
    "            if ss == 'H':\n",
    "                expoinfo['percent_H-dssp'] = count/total\n",
    "            if ss == 'B':\n",
    "                expoinfo['percent_B-dssp'] = count/total\n",
    "            if ss == 'E':\n",
    "                expoinfo['percent_E-dssp'] = count/total\n",
    "            if ss == 'G':\n",
    "                expoinfo['percent_G-dssp'] = count/total\n",
    "            if ss == 'I':\n",
    "                expoinfo['percent_I-dssp'] = count/total\n",
    "            if ss == 'T':\n",
    "                expoinfo['percent_T-dssp'] = count/total\n",
    "            if ss == 'S':\n",
    "                expoinfo['percent_S-dssp'] = count/total\n",
    "\n",
    "        # Filling in 0 percenters\n",
    "        for per in ['percent_C-dssp','percent_H-dssp','percent_B-dssp','percent_E-dssp',\n",
    "                    'percent_G-dssp','percent_I-dssp','percent_T-dssp','percent_S-dssp']:\n",
    "            if per not in expoinfo:\n",
    "                expoinfo[per] = 0.0\n",
    "\n",
    "        infodict[chain] = dict(expoinfo)\n",
    "\n",
    "    return infodict\n",
    "\n",
    "\n",
    "# TODO: below methods have not been fixed\n",
    "def calc_surface_buried(dssp_df):\n",
    "    '''Calculates the percent of residues that are in the surface or buried,\n",
    "    as well as if they are polar or nonpolar. Returns a dictionary of this.\n",
    "    '''\n",
    "    SN = 0\n",
    "    BN = 0\n",
    "    SP = 0\n",
    "    SNP = 0\n",
    "    SPo = 0\n",
    "    SNe = 0\n",
    "    BNP = 0\n",
    "    BP = 0\n",
    "    BPo = 0\n",
    "    BNe = 0\n",
    "    Total = 0\n",
    "\n",
    "    sbinfo = {}\n",
    "\n",
    "    df_min = dssp_df[['aa_three', 'exposure_asa']]\n",
    "\n",
    "    if len(df_min) == 0:\n",
    "        return sbinfo\n",
    "    else:\n",
    "        for i, r in df_min.iterrows():\n",
    "            res = r.aa_three\n",
    "            area = r.exposure_asa\n",
    "            if res in AAdict:\n",
    "                if AAdict[res] == 'nonpolar' and area > 3:\n",
    "                    SNP = SNP + 1\n",
    "                    SN = SN + 1\n",
    "                elif AAdict[res] == 'polar' and area > 3:\n",
    "                    SP = SP + 1\n",
    "                    SN = SN + 1\n",
    "                elif AAdict[res] == 'positive' and area > 3:\n",
    "                    SPo = SPo + 1\n",
    "                    SN = SN + 1\n",
    "                elif AAdict[res] == 'negative' and area > 3:\n",
    "                    SNe = SNe + 1\n",
    "                    SN = SN + 1\n",
    "                elif AAdict[res] == 'positive' and area <= 3:\n",
    "                    BPo = BPo + 1\n",
    "                    BN = BN + 1\n",
    "                elif AAdict[res] == 'negative' and area <= 3:\n",
    "                    BNe = BNe + 1\n",
    "                    BN = BN + 1\n",
    "                elif AAdict[res] == 'polar' and area <= 3:\n",
    "                    BP = BP + 1\n",
    "                    BN = BN + 1\n",
    "                elif AAdict[res] == 'nonpolar' and area <= 3:\n",
    "                    BNP = BNP + 1\n",
    "                    BN = BN + 1\n",
    "        Total = float(BN + SN)\n",
    "        pSNP = float(SNP) / Total\n",
    "        pSP = float(SP) / Total\n",
    "        pSPo = float(SPo) / Total\n",
    "        pSNe = float(SNe) / Total\n",
    "        pBNP = float(BNP) / Total\n",
    "        pBP = float(BP) / Total\n",
    "        pBPo = float(BPo) / Total\n",
    "        pBNe = float(BNe) / Total\n",
    "        pBN = float(BN) / Total\n",
    "        pSN = float(SN) / Total\n",
    "        sbinfo['ssb_per_S_NP'] = pSNP\n",
    "        sbinfo['ssb_per_S_P'] = pSP\n",
    "        sbinfo['ssb_per_S_pos'] = pSPo\n",
    "        sbinfo['ssb_per_S_neg'] = pSNe\n",
    "        sbinfo['ssb_per_B_NP'] = pBNP\n",
    "        sbinfo['ssb_per_B_P'] = pBP\n",
    "        sbinfo['ssb_per_B_pos'] = pBPo\n",
    "        sbinfo['ssb_per_B_neg'] = pBNe\n",
    "        sbinfo['ssb_per_S'] = pSN\n",
    "        sbinfo['ssb_per_B'] = pBN\n",
    "\n",
    "        return sbinfo\n",
    "\n",
    "\n",
    "def calc_sasa(dssp_df):\n",
    "    \"\"\"\n",
    "    Calculation of SASA utilizing the DSSP program.\n",
    "\n",
    "    DSSP must be installed for biopython to properly call it.\n",
    "    Install using apt-get on Ubuntu\n",
    "    or from: http://swift.cmbi.ru.nl/gv/dssp/\n",
    "\n",
    "    Input: PDB or CIF structure file\n",
    "    Output: SASA (integer) of structure\n",
    "    \"\"\"\n",
    "\n",
    "    infodict = {'ssb_sasa': dssp_df.exposure_asa.sum(),\n",
    "                'ssb_mean_rel_exposed': dssp_df.exposure_rsa.mean(),\n",
    "                'ssb_size': len(dssp_df)}\n",
    "\n",
    "    return infodict\n",
    "\n",
    "\n",
    "def all_dssp_props(filename, file_type):\n",
    "    '''Returns a large dictionary of SASA, secondary structure\n",
    "    composition, and surface/buried composition. Values are computed using DSSP.\n",
    "    Input: PDB or MMCIF filename\n",
    "    Output: Dictionary of values obtained from dssp\n",
    "    '''\n",
    "    t = dssp_dataframe(filename, file_type)\n",
    "    # print(t)\n",
    "    sasa = calc_sasa(t)\n",
    "    sstr = secondary_structure_summary(t)\n",
    "    subu = calc_surface_buried(t)\n",
    "\n",
    "    sasa.update(sstr)\n",
    "    sasa.update(subu)\n",
    "\n",
    "    return sasa\n",
    "\n",
    "\n",
    "def get_ss_class(pdb_file, dssp_file, chain):\n",
    "    \"\"\"Define the secondary structure class of a PDB file at the specific chain\n",
    "\n",
    "    Args:\n",
    "        pdb_file:\n",
    "        dssp_file:\n",
    "        chain:\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    prag = pr.parsePDB(pdb_file)\n",
    "    pr.parseDSSP(dssp_file, prag)\n",
    "    alpha, threeTen, beta = get_dssp_ss_content_multiplechains(prag, chain)\n",
    "\n",
    "    if alpha == 0 and beta > 0:\n",
    "        classification = 'all-beta'\n",
    "    elif beta == 0 and alpha > 0:\n",
    "        classification = 'all-alpha'\n",
    "    elif beta == 0 and alpha == 0:\n",
    "        classification = 'mixed'\n",
    "    elif float(alpha) / beta >= 20:\n",
    "        classification = 'all-alpha'\n",
    "    else:\n",
    "        classification = 'mixed'\n",
    "\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YiD-20YtsdgF"
   },
   "source": [
    "# Change of stability landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zh0BG-Q2stFS"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"results/{prot_interest}.csv\")\n",
    "\n",
    "df[\"resnum\"] = df.variant.apply(lambda x: int(x[1:-1]))\n",
    "df[\"aa\"] = df.variant.apply(lambda x: x[0])\n",
    "df[\"to\"] = df.variant.apply(lambda x: x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pbn5LmWYJyCo"
   },
   "outputs": [],
   "source": [
    "dssp = get_dssp_df_on_file(f\"./data/pdbs/cleaned/{prot_interest}_clean.pdb\",\n",
    "                           force_rerun=True)\n",
    "\n",
    "# adding the relative accessibility to the DSSP dataframe\n",
    "dssp['rel_acc'] = dssp['exposure_rsa']/dssp['max_acc'] # WHERE REL_ACC REPRENSENTS THE PROPORTION OF RSA, NOT RSA ITSELF\n",
    "\n",
    "# Defining cutoffs for classification of the positions into core, boundary and surface\n",
    "classification = []\n",
    "for i in dssp['rel_acc']:\n",
    "    if i < 0.1:\n",
    "        classification.append('core')\n",
    "    if 0.1 <= i < 0.4:\n",
    "        classification.append('boundary')\n",
    "    if i >= 0.4:\n",
    "        classification.append('surface')\n",
    "\n",
    "# adding the classifications as a column to the dssp dataframe\n",
    "dssp['classification'] = classification\n",
    "\n",
    "# Merge dssp info with df variants\n",
    "df = pd.merge(df, dssp, how='left', on=['resnum','aa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lttbb5GxPMIn"
   },
   "outputs": [],
   "source": [
    "def get_xlabels(resnum, aa):\n",
    "    if resnum < 9:\n",
    "        return f\" {resnum} {aa}\"\n",
    "    else:\n",
    "        return f\"{resnum} {aa}\"\n",
    "\n",
    "wt_seq = df[[\"resnum\", \"aa\"]].drop_duplicates(\n",
    "\n",
    "    ).apply(lambda x: get_xlabels(x['resnum'], x['aa']), axis=1\n",
    "    ).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_8U_Lq8NYaCG"
   },
   "outputs": [],
   "source": [
    "aa_to_feature_mapper = {\n",
    "    \"D\": \"acidic\", \"E\": \"acidic\",\n",
    "    \"H\": \"basic\", \"K\": \"basic\", \"R\": \"basic\",\n",
    "    \"A\": \"hydrophobic\", \"F\": \"hydrophobic\", \"I\": \"hydrophobic\", \"L\": \"hydrophobic\", \"M\": \"hydrophobic\", \"V\": \"hydrophobic\", \"Y\": \"hydrophobic\", \"W\": \"hydrophobic\",\n",
    "    \"N\": \"polar\", \"Q\": \"polar\", \"S\": \"polar\", \"T\": \"polar\",\n",
    "    \"G\": \"special\", \"P\": \"special\", \"C\": \"special\",\n",
    "    }\n",
    "\n",
    "df[\"aa_feature\"] = df[\"to\"].apply(lambda x: aa_to_feature_mapper[x])\n",
    "\n",
    "# Specify order of target residues:\n",
    "aa_order = [\"D\", \"E\", \"H\", \"K\", \"R\", \"A\", \"F\", \"I\", \"L\", \"M\", \"V\", \"Y\", \"W\", \"N\", \"Q\", \"S\", \"T\", \"G\", \"P\", \"C\"]\n",
    "dict_aa_order = {}\n",
    "for i, aa in enumerate(aa_order):\n",
    "    dict_aa_order[aa] = i\n",
    "df = df.sort_values(by=\"to\", key=lambda x: x.map(dict_aa_order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QhztPcM_uDcD"
   },
   "outputs": [],
   "source": [
    "dir_path = \"results\"\n",
    "list_ddg_dddg_cols = [\"ddg\", \"ddg_ds_mayo\", \"ddg_ds_guerois\"]\n",
    "list_titles = [\"Cavity model\",\n",
    "               \"Cavity + DS (Mayo) models\",\n",
    "               \"Cavity + DS (Guerois) models\"]\n",
    "ddg_labels = [\"\\u0394\\u0394G (kcal/mol)\"]*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mx_YJAGaXQr6"
   },
   "outputs": [],
   "source": [
    "df.sort_values(by=[\"resnum\", \"aa\", \"to\"])[[\"resnum\", \"aa\", \"to\", \"ddg_ds_mayo\"]][:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2228,
     "status": "ok",
     "timestamp": 1620928877930,
     "user": {
      "displayName": "Jean-Baptiste Van Den Broucke",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtaGEPCQbJCZvlt0pnd8zp8Lr7aa-YohqINw_9vg=s64",
      "userId": "13204566160110856358"
     },
     "user_tz": -120
    },
    "id": "D9sAJ4ap2vuZ",
    "outputId": "7266b311-f20a-4672-b317-b8b95da15998"
   },
   "outputs": [],
   "source": [
    "# Get the indexes of the core residues\n",
    "list_core_pos = np.array(df[df[\"classification\"] == \"core\"][\"resnum\"].unique() - 1)\n",
    "\n",
    "# mask of indices not in core\n",
    "mask = np.ones_like(wt_seq, dtype=bool)\n",
    "mask[list_core_pos] = False\n",
    "\n",
    "# get the plot with plotly and the proper layout (tip: two heatmap traces)\n",
    "xrange_ = np.arange(df.resnum.min(), df.resnum.max()+1)\n",
    "\n",
    "for ddg_value, title, label in zip(list_ddg_dddg_cols, list_titles, ddg_labels):\n",
    "    print(title)\n",
    "    trace = [go.Heatmap(\n",
    "        x = df['resnum'],\n",
    "        y = [df[\"aa_feature\"], df['to']],\n",
    "        z = df[ddg_value],\n",
    "        type = 'heatmap',\n",
    "        colorscale = 'RdBu_r',\n",
    "        zmid=0,\n",
    "        colorbar={\"title\":label, \"titleside\":\"right\", \"tickangle\":-90}\n",
    "    ), go.Heatmap(xaxis='x2')]\n",
    "    # data = trace\n",
    "    layout = go.Layout(\n",
    "        xaxis=dict( # core positions\n",
    "            range=[xrange_[0]-0.5, xrange_[-1]+0.5],\n",
    "            title=\"G\\u03B21 primary structure\",\n",
    "            tickfont=dict(color=\"#1f77b4\"),\n",
    "            tickmode=\"array\",\n",
    "            tickangle=-90,\n",
    "            tickvals=list(xrange_[mask]),\n",
    "            ticktext=list(wt_seq[mask])\n",
    "            ),\n",
    "        xaxis2=dict( # non-core positions\n",
    "            range=[xrange_[0]-0.5, xrange_[-1]+0.5],\n",
    "            tickfont=dict(color=\"#ff7f0e\"),\n",
    "            tickmode=\"array\",\n",
    "            tickangle=-90,\n",
    "            tickvals=list(xrange_[~mask]),\n",
    "            ticktext=list(wt_seq[~mask]),\n",
    "            overlaying=\"x\"\n",
    "            ),\n",
    "        yaxis=dict(\n",
    "            title=\"Target\",\n",
    "            tickangle=-90\n",
    "            ),\n",
    "        # title=title\n",
    "        )\n",
    "    fig = go.Figure(data=trace, layout=layout)\n",
    "    fig.write_html(f\"{dir_path}/heatmap_{ddg_value}_{prot_interest}.html\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "executionInfo": {
     "elapsed": 3192,
     "status": "ok",
     "timestamp": 1620928913270,
     "user": {
      "displayName": "Jean-Baptiste Van Den Broucke",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtaGEPCQbJCZvlt0pnd8zp8Lr7aa-YohqINw_9vg=s64",
      "userId": "13204566160110856358"
     },
     "user_tz": -120
    },
    "id": "z1VlSv9NSkhJ",
    "outputId": "1f3b937d-a5cd-41d7-be96-bd943f8a5f99"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4),\n",
    "                         constrained_layout=True, sharey=True)\n",
    "\n",
    "for i, (ax, ddg_value, title) in enumerate(zip(axes, list_ddg_dddg_cols[:5], list_titles[:5])):\n",
    "    x = pd.Series(df[ddg_value], name='\\u0394\\u0394G (kcal/mol)')\n",
    "    sns.histplot(x, kde=False, bins=25, stat=\"probability\",\n",
    "                 color=\"grey\", edgecolor='black',\n",
    "                 ax=ax,\n",
    "                 zorder=10).set(ylabel=\"Fraction of Total Library\")\n",
    "    ax.axvline(x.median(), color='r', linestyle='dashed', linewidth=1, label=\"median\")\n",
    "    ax.grid(axis=\"y\", linestyle='dashed', alpha=0.7)\n",
    "    legend = ax.legend()\n",
    "    frame = legend.get_frame()\n",
    "    frame.set_facecolor('white')\n",
    "    frame.set_edgecolor('black')\n",
    "    ax.set_title(title)\n",
    "plt.savefig(f\"{dir_path}/stability_distribution_{prot_interest}.png\", dpi=200, bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pk5VWiU6XV2p"
   },
   "source": [
    "## Save predictions in .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dLUyDqD-nmOB"
   },
   "outputs": [],
   "source": [
    "# df.sort_values(by=[\"resnum\", \"aa\", \"to\"])[[\"pdbid\", \"chainid\", \"variant\", \"ddg\", \"ddg_ds_mayo\", \"ddg_ds_guerois\"]].to_csv(f\"{dir_path}/{prot_interest}_cav_model_pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_interest"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPgK3+zL6JHlyw7k6JdgX2n",
   "collapsed_sections": [
    "gRUgirV29hV8",
    "EEoW1oaG6ZTn",
    "33gJF-wL8Z9j",
    "GAWXxcHfnqHk",
    "NkeuxIuAZFxM",
    "xnwPnabm0lKg",
    "qrz-6ax2O505",
    "YiD-20YtsdgF"
   ],
   "name": "deployment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cav_model",
   "language": "python",
   "name": "cav_model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
